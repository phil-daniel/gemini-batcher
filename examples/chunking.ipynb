{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fbfbc6a",
      "metadata": {
        "id": "7fbfbc6a"
      },
      "source": [
        "# Chunking Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc676ff",
      "metadata": {
        "id": "bcc676ff"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f4a2af76",
      "metadata": {
        "id": "f4a2af76",
        "outputId": "7499b888-5aca-4bba-b305-13cc69bd6e03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U -q \"google-genai>=1.0.0\"  # Install the Python SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b25fb9",
      "metadata": {
        "id": "20b25fb9"
      },
      "source": [
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](../quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bc937084",
      "metadata": {
        "id": "bc937084"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "MODEL_ID = \"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a0007cd0",
      "metadata": {
        "id": "a0007cd0"
      },
      "outputs": [],
      "source": [
        "from google.genai import types\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import math\n",
        "\n",
        "questions = requests.get(\"https://raw.githubusercontent.com/phil-daniel/gemini-batcher/refs/heads/main/examples/demo_files/questions.txt\").text.split('\\n')\n",
        "content = requests.get(\"https://raw.githubusercontent.com/phil-daniel/gemini-batcher/refs/heads/main/examples/demo_files/content.txt\").text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a68ba2",
      "metadata": {
        "id": "13a68ba2"
      },
      "source": [
        "# Chunking example 1 - fixed chunking\n",
        "In fixed chunking, the content is split into non-overlapping chunks each containing a set number of characters, in this case 10,000. An example of this can be seen below.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/phil-daniel/gemini-batcher/refs/heads/main/docs/concepts/images/fixed_chunking.svg\" alt=\"A visual example of fixed chunking.\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "82cfc3b7",
      "metadata": {
        "id": "82cfc3b7",
        "outputId": "92c35120-2bc4-488c-953b-6a02a08ad8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 6\n"
          ]
        }
      ],
      "source": [
        "chunk_char_size = 10000\n",
        "chunked_content = []\n",
        "chunk_count = math.ceil(len(content) / chunk_char_size)\n",
        "\n",
        "for i in range(chunk_count):\n",
        "    chunk_start_pos = i * chunk_char_size\n",
        "    chunk_end_pos = min(chunk_start_pos + chunk_char_size, len(content))\n",
        "    chunked_content.append(content[chunk_start_pos : chunk_end_pos])\n",
        "\n",
        "print(f'Number of chunks: {len(chunked_content)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f12a5fe2",
      "metadata": {
        "id": "f12a5fe2"
      },
      "source": [
        "## Chunking example 2 - sliding window chunking\n",
        "One disadvantage of fixed chunking is that since it breaks context at arbitrary positions, important information may get split between chunks, meaning that neither chunk contains enough information to fully answer a question.\n",
        "\n",
        "A simple solution to this is to follow a sliding window approach, where an overlap (called the window) between adjacent chunks is introduced. This increases the likelihood that a complete answer can be found within a single chunk, however can also increase the total number of chunks.\n",
        "\n",
        "An example of this can be seen below.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/phil-daniel/gemini-batcher/refs/heads/main/docs/concepts/images/sliding_window.svg\" alt=\"A visual example of sliding window chunking.\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ea95b521",
      "metadata": {
        "id": "ea95b521",
        "outputId": "ab674cc7-db67-4cb6-91a3-4126f8739419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 8\n"
          ]
        }
      ],
      "source": [
        "chunk_char_size = 10000\n",
        "window_char_size = 2500\n",
        "\n",
        "chunked_content = []\n",
        "chunk_count = math.ceil(len(content) / (chunk_char_size - window_char_size))\n",
        "\n",
        "for i in range(chunk_count):\n",
        "    chunk_start_pos = i * (chunk_char_size - window_char_size)\n",
        "    chunk_end_pos = min(chunk_start_pos + chunk_char_size, len(content))\n",
        "    chunked_content.append(content[chunk_start_pos : chunk_end_pos])\n",
        "\n",
        "print(f'Number of chunks: {len(chunked_content)}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gsoc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}